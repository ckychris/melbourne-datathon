{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is heading for Diabetes?\n",
    "\n",
    "This is the predictive part of the 2017 Melbourne Datathon.\n",
    "\n",
    "The task is to predict the probability that a patient will be dispensed a drug related to Diabetes post 2015. This is quite important research as it will be an early warning system for doctors so intervention can potentially be made before it is too late.\n",
    "\n",
    "Use the patients that we have provided all the records for to build your model, then see how it performs on these unseen people.\n",
    "\n",
    "For patient ID'S 279,201 to 558,352 you need to submit a file with 2 columns, the Patient_ID and the probability in the range [0-1]. The file will have 279,153 rows including the header row. An example submission file is provided for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/datasets.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_patient_data(connection, patient_id):\n",
    "    \"\"\"\n",
    "    Return the patient data.\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "SELECT *\n",
    "FROM transactions a\n",
    "LEFT OUTER JOIN ChronicIllness_LookUp b \n",
    "    ON a.Drug_ID = b.MasterProductID \n",
    "LEFT OUTER JOIN patients c\n",
    "    ON a.Patient_ID = c.Patient_ID\n",
    "LEFT OUTER JOIN classification d\n",
    "    ON a.Patient_ID = d.Patient_ID\n",
    "LEFT OUTER JOIN social e\n",
    "    ON c.postcode = e.postcode\n",
    "WHERE a.Patient_ID = {}\n",
    "AND a.prescription_week < '2016-01-01'\n",
    "ORDER BY prescription_week\n",
    "    \"\"\".format(patient_id)\n",
    "\n",
    "    return pd.read_sql_query(SQL, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_map = {'F': 1, 'M': 0, 'U': 0.5}\n",
    "\n",
    "def gender(patient_data):\n",
    "    return gender_map[patient_data.gender[0]]\n",
    "\n",
    "def age(patient_data):\n",
    "    patient_age = 2016 - patient_data.year_of_birth[0]\n",
    "    if patient_age > 100: \n",
    "        return 0.5 \n",
    "    else: \n",
    "        return patient_age / 100.\n",
    "\n",
    "def socio_score(patient_data):\n",
    "    score = patient_data.disadvantage_score[0]\n",
    "    if isinstance(score, str):\n",
    "        return 1.\n",
    "    if score is None:\n",
    "        return 1.\n",
    "    return float(score) / 1000.\n",
    "\n",
    "def diabetes(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Diabetes').any())\n",
    "\n",
    "def lipids(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Lipids').any())\n",
    "\n",
    "def hypertension(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Hypertension').any())\n",
    "\n",
    "def heart_failure(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Heart Failure').any())\n",
    "\n",
    "def osteoporosis(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Osteoporosis').any())\n",
    "\n",
    "def depression(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Depression').any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute some basic features of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(patient_frame):\n",
    "    \"\"\"\n",
    "    Form a feature dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    return {'gender': gender(patient_frame), \n",
    "            'age': age(patient_frame), \n",
    "            'socio_score': socio_score(patient_frame),\n",
    "            'diabetes': diabetes(patient_frame),\n",
    "            'lipids': lipids(patient_frame),\n",
    "            'hypertension': hypertension(patient_frame),\n",
    "            'heart_failure':heart_failure(patient_frame),\n",
    "            'osteoporosis': osteoporosis(patient_frame),\n",
    "            'depression': depression(patient_frame),\n",
    "            'target': patient_frame.Target[0]}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a random sample of patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20000\n",
    "patient_ids = np.random.randint(0, 279201, n)\n",
    "patient_data = []\n",
    "for patient_id in tqdm.tqdm_notebook(patient_ids):\n",
    "    patient_data.append(retrieve_patient_data(conn, patient_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features into a feature dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for patient in tqdm.tqdm_notebook(patient_data): \n",
    "    features.append(feature_extract(patient))\n",
    "feature_frame = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the features to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_frame.to_csv('../submissions/features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adhoc features\n",
    "\n",
    "An example of updating the feature frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_feature(patient_frame):\n",
    "    return float(patient_frame.ChronicIllness.str.contains('Diabetes').any())\n",
    "\n",
    "feature_vector = []\n",
    "for patient in tqdm.tqdm_notebook(patient_data): \n",
    "    feature_vector.append(custom_feature(patient))\n",
    "\n",
    "feature_frame['custom'] = feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the feature we have extracted\n",
    "\n",
    "Note: not sure here - trying out something from scikit learn but it may not be sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = feature_frame.groupby('target').mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out a set of different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the feature matrix is usually transformed to have zero mean and unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_frame.drop('target', axis=1).values\n",
    "y = feature_frame.target.values\n",
    "\n",
    "X_transformed = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the data into test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ('Random Forrest', RandomForestClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Adaboost',AdaBoostClassifier() ),\n",
    "    ('SVM',SVC(probability=True))]\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    print('Classifier: {}'.format(name))\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test, clf.predict(X_test) \n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form a submission\n",
    "\n",
    "Perform the prediction in 1000 patient \"chunks\" to speed up the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../../submissions/diabetes_submission_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chunks = submission.groupby(np.arange(len(submission)) // 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, frame in tqdm.tqdm_notebook(chunks):\n",
    "    \n",
    "    # Extract the features\n",
    "    data = [feature_extract(patient_data(conn, x)) for x in frame.Patient_ID.values]\n",
    "    \n",
    "    # Construct prediction X matrix\n",
    "    pred_x = np.vstack([x[0] for x in data])\n",
    "    \n",
    "    # Make sure we don't have nans in the data\n",
    "    pred_x[np.isnan(pred_x)] = 0\n",
    "    \n",
    "    # Apply the standard transform prior to fitting. \n",
    "    pred_x = StandardScaler().fit_transform(pred_x)\n",
    "    \n",
    "    # Fit the model\n",
    "    submission.Diabetes[frame.index] = model.predict_proba(pred_x)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../../submissions/kaggle.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
