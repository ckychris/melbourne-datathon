{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who is heading for Diabetes?\n",
    "\n",
    "This is the predictive part of the 2017 Melbourne Datathon.\n",
    "\n",
    "The task is to predict the probability that a patient will be dispensed a drug related to Diabetes post 2015. This is quite important research as it will be an early warning system for doctors so intervention can potentially be made before it is too late.\n",
    "\n",
    "Use the patients that we have provided all the records for to build your model, then see how it performs on these unseen people.\n",
    "\n",
    "For patient ID'S 279,201 to 558,352 you need to submit a file with 2 columns, the Patient_ID and the probability in the range [0-1]. The file will have 279,153 rows including the header row. An example submission file is provided for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/datasets.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_patient_data(connection, patient_id):\n",
    "    \"\"\"\n",
    "    Return the patient data.\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "SELECT *\n",
    "FROM transactions a\n",
    "LEFT OUTER JOIN ChronicIllness_LookUp b \n",
    "    ON a.Drug_ID = b.MasterProductID \n",
    "LEFT OUTER JOIN patients c\n",
    "    ON a.Patient_ID = c.Patient_ID\n",
    "LEFT OUTER JOIN classification d\n",
    "    ON a.Patient_ID = d.Patient_ID\n",
    "LEFT OUTER JOIN social e\n",
    "    ON c.postcode = e.postcode\n",
    "WHERE a.Patient_ID = {}\n",
    "AND a.prescription_week < '2016-01-01'\n",
    "ORDER BY prescription_week\n",
    "    \"\"\".format(patient_id)\n",
    "\n",
    "    return pd.read_sql_query(SQL, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender_map = {'F': 1, 'M': 0, 'U': 0.5}\n",
    "\n",
    "def gender(patient_data):\n",
    "    return gender_map[patient_data.gender[0]]\n",
    "\n",
    "def age(patient_data):\n",
    "    patient_age = 2016 - patient_data.year_of_birth[0]\n",
    "    if patient_age > 100: \n",
    "        return 0.5 \n",
    "    else: \n",
    "        return patient_age / 100.\n",
    "\n",
    "def socio_score(patient_data):\n",
    "    score = patient_data.disadvantage_score[0]\n",
    "    if isinstance(score, str):\n",
    "        return 1.\n",
    "    if score is None:\n",
    "        return 1.\n",
    "    return float(score) / 1000.\n",
    "\n",
    "def diabetes(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Diabetes').any())\n",
    "\n",
    "def lipids(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Lipids').any())\n",
    "\n",
    "def hypertension(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Hypertension').any())\n",
    "\n",
    "def heart_failure(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Heart Failure').any())\n",
    "\n",
    "def osteoporosis(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Osteoporosis').any())\n",
    "\n",
    "def depression(patient_data):\n",
    "    return float(patient_data.ChronicIllness.str.contains('Depression').any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute some basic features of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(patient_frame):\n",
    "    \"\"\"\n",
    "    Form a feature dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    return {'gender': gender(patient_frame), \n",
    "            'age': age(patient_frame), \n",
    "            'socio_score': socio_score(patient_frame),\n",
    "            'diabetes': diabetes(patient_frame),\n",
    "            'lipids': lipids(patient_frame),\n",
    "            'hypertension': hypertension(patient_frame),\n",
    "            'heart_failure':heart_failure(patient_frame),\n",
    "            'osteoporosis': osteoporosis(patient_frame),\n",
    "            'depression': depression(patient_frame),\n",
    "            'target': patient_frame.Target[0]}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a random sample of patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "patient_ids = np.random.randint(0, 279201, n)\n",
    "patient_data = []\n",
    "for patient_id in tqdm.tqdm_notebook(patient_ids):\n",
    "    patient_data.append(retrieve_patient_data(conn, patient_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features into a feature dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for patient in tqdm.tqdm_notebook(patient_data): \n",
    "    features.append(feature_extract(patient))\n",
    "feature_frame = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the features and ?patient data? to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frame.to_csv('../submissions/features.csv')\n",
    "\n",
    "with open('../submissions/patient_data.pkl', 'wb') as fh:\n",
    "    pickle.dump(patient_data, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frame = pd.read_csv('../submissions/features.csv')\n",
    "\n",
    "with open('../submissions/patient_data.pkl', 'rb') as fh:\n",
    "    patient_data = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adhoc features\n",
    "\n",
    "An example of updating the feature frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103404083e3444bb96d8ad6c011a6d21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def custom_feature(patient_frame):\n",
    "    \n",
    "    codes = {\n",
    "     'A': 0, # Unknown\n",
    "     'C': 0, # Unknown   \n",
    "     'Z': 0, # Unknown\n",
    "     'N': 0, # NHS Script\n",
    "     'P': 0, # Private Script\n",
    "     'B': 0, # Doctors Bag Script\n",
    "     'T': 0, # Schedule Three Recordable Script\n",
    "     'R': 0, # Repatriation Script\n",
    "     'D': 0, # Dental Script\n",
    "     'E': 0, # Optometrist Script\n",
    "     'U': 0, # Nurse Practitioner Script\n",
    "     'F': 0  # Midwife Script\n",
    "    }\n",
    "    \n",
    "    codes.update(patient_frame.SourceSystem_Code.value_counts(normalize=True).to_dict())\n",
    "    return codes\n",
    "\n",
    "features = []\n",
    "for patient in tqdm.tqdm_notebook(patient_data): \n",
    "    features.append(custom_feature(patient))\n",
    "\n",
    "features = pd.DataFrame(features)\n",
    "features.columns = ['system_code_'+ x.lower() for x in features.columns]\n",
    "feature_frame = pd.concat( [feature_frame, features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af46e934833445dbb1d523646fc1c2d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def mean_script_time(patient_frame):\n",
    "    script_week_diff = pd.to_datetime(patient_frame.Prescription_Week).diff()\n",
    "    return script_week_diff[script_week_diff > pd.Timedelta(0)].mean() / pd.Timedelta(days=365*6)\n",
    "\n",
    "features = []\n",
    "for patient in tqdm.tqdm_notebook(patient_data): \n",
    "    features.append(mean_script_time(patient))\n",
    "feature_frame['mean_script_time'] = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the feature we have extracted\n",
    "\n",
    "Note: not sure here - trying out something from scikit learn but it may not be sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>depression</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>gender</th>\n",
       "      <th>heart_failure</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>lipids</th>\n",
       "      <th>osteoporosis</th>\n",
       "      <th>socio_score</th>\n",
       "      <th>...</th>\n",
       "      <th>system_code_d</th>\n",
       "      <th>system_code_e</th>\n",
       "      <th>system_code_f</th>\n",
       "      <th>system_code_n</th>\n",
       "      <th>system_code_p</th>\n",
       "      <th>system_code_r</th>\n",
       "      <th>system_code_t</th>\n",
       "      <th>system_code_u</th>\n",
       "      <th>system_code_z</th>\n",
       "      <th>mean_script_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001.409290</td>\n",
       "      <td>0.510346</td>\n",
       "      <td>0.343941</td>\n",
       "      <td>0.060595</td>\n",
       "      <td>0.576201</td>\n",
       "      <td>0.309071</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.578639</td>\n",
       "      <td>0.071934</td>\n",
       "      <td>0.989911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.056454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4990.790323</td>\n",
       "      <td>0.509538</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.938821</td>\n",
       "      <td>0.511123</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.543938</td>\n",
       "      <td>0.855395</td>\n",
       "      <td>0.037820</td>\n",
       "      <td>0.981688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.898247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.044154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       age  depression  diabetes    gender  heart_failure  \\\n",
       "target                                                                         \n",
       "0       5001.409290  0.510346    0.343941  0.060595  0.576201       0.309071   \n",
       "1       4990.790323  0.509538    0.290323  0.938821  0.511123       0.370968   \n",
       "\n",
       "        hypertension    lipids  osteoporosis  socio_score        ...         \\\n",
       "target                                                           ...          \n",
       "0           0.438917  0.578639      0.071934     0.989911        ...          \n",
       "1           0.543938  0.855395      0.037820     0.981688        ...          \n",
       "\n",
       "        system_code_d  system_code_e  system_code_f  system_code_n  \\\n",
       "target                                                               \n",
       "0                 0.0            0.0       0.919429            0.0   \n",
       "1                 0.0            0.0       0.898247            0.0   \n",
       "\n",
       "        system_code_p  system_code_r  system_code_t  system_code_u  \\\n",
       "target                                                               \n",
       "0                 0.0            0.0            0.0            0.0   \n",
       "1                 0.0            0.0            0.0            0.0   \n",
       "\n",
       "        system_code_z  mean_script_time  \n",
       "target                                   \n",
       "0            0.002718          0.056454  \n",
       "1            0.000545          0.044154  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = feature_frame.groupby('target').mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out a set of different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the feature matrix is usually transformed to have zero mean and unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a505ad58e853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/nathan/conda/envs/kaggle/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nathan/conda/envs/kaggle/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nathan/conda/envs/kaggle/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    581\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    582\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nathan/conda/envs/kaggle/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nathan/conda/envs/kaggle/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "X = feature_frame.drop('target', axis=1).values\n",
    "y = feature_frame.target.values\n",
    "\n",
    "X_transformed = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the data into test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ('Random Forrest', RandomForestClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Adaboost',AdaBoostClassifier() ),\n",
    "    ('SVM',SVC(probability=True))]\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    print('Classifier: {}'.format(name))\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test, clf.predict(X_test) \n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form a submission\n",
    "\n",
    "Perform the prediction in 1000 patient \"chunks\" to speed up the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../../submissions/diabetes_submission_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chunks = submission.groupby(np.arange(len(submission)) // 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, frame in tqdm.tqdm_notebook(chunks):\n",
    "    \n",
    "    # Extract the features\n",
    "    data = [feature_extract(patient_data(conn, x)) for x in frame.Patient_ID.values]\n",
    "    \n",
    "    # Construct prediction X matrix\n",
    "    pred_x = np.vstack([x[0] for x in data])\n",
    "    \n",
    "    # Make sure we don't have nans in the data\n",
    "    pred_x[np.isnan(pred_x)] = 0\n",
    "    \n",
    "    # Apply the standard transform prior to fitting. \n",
    "    pred_x = StandardScaler().fit_transform(pred_x)\n",
    "    \n",
    "    # Fit the model\n",
    "    submission.Diabetes[frame.index] = model.predict_proba(pred_x)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../../submissions/kaggle.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
