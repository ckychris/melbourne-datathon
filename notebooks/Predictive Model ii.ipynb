{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Who is heading for Diabetes?\n",
    "\n",
    "This is the predictive part of the 2017 Melbourne Datathon.\n",
    "\n",
    "The task is to predict the probability that a patient will be dispensed a drug related to Diabetes post 2015. This is quite important research as it will be an early warning system for doctors so intervention can potentially be made before it is too late.\n",
    "\n",
    "Use the patients that we have provided all the records for to build your model, then see how it performs on these unseen people.\n",
    "\n",
    "For patient ID'S 279,201 to 558,352 you need to submit a file with 2 columns, the Patient_ID and the probability in the range [0-1]. The file will have 279,153 rows including the header row. An example submission file is provided for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-26T13:04:10.059649Z",
     "start_time": "2017-04-26T13:04:10.041756Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sqlite3\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Data retrieval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-26T01:44:02.805824Z",
     "start_time": "2017-04-26T01:44:02.802822Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/datasets.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-27T22:57:04.765392Z",
     "start_time": "2017-04-27T22:57:04.745756Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_patient_data(connection, patient_id):\n",
    "    \"\"\"\n",
    "    Return the patient data.\n",
    "    \"\"\"\n",
    "    SQL = \"\"\"\n",
    "SELECT *\n",
    "FROM transactions a\n",
    "LEFT OUTER JOIN ChronicIllness_LookUp b \n",
    "    ON a.Drug_ID = b.MasterProductID \n",
    "LEFT OUTER JOIN patients c\n",
    "    ON a.Patient_ID = c.Patient_ID\n",
    "LEFT OUTER JOIN classification d\n",
    "    ON a.Patient_ID = d.Patient_ID\n",
    "LEFT OUTER JOIN social e\n",
    "    ON c.postcode = e.postcode\n",
    "WHERE a.Patient_ID = {}\n",
    "AND a.prescription_week < '2016-01-01'\n",
    "ORDER BY prescription_week\n",
    "    \"\"\".format(patient_id)\n",
    "\n",
    "    return pd.read_sql_query(SQL, connection)\n",
    "\n",
    "\n",
    "def retrieve_chronic_illness(connection):\n",
    "    SQL = \"\"\"\n",
    "SELECT DISTINCT ChronicIllness FROM ChronicIllness_LookUp \n",
    "    \"\"\".format(patient_id)\n",
    "    return pd.read_sql_query(SQL, connection)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-27T23:00:46.063207Z",
     "start_time": "2017-04-27T23:00:45.909155Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gender_map = {'F': 1, 'M': 0, 'U': 0.5}\n",
    "\n",
    "def gender(patient_frame):\n",
    "    return gender_map[patient_frame.gender[0]]\n",
    "\n",
    "def age(patient_frame):\n",
    "    patient_age = 2016 - patient_frame.year_of_birth[0]\n",
    "    if patient_age > 100: \n",
    "        return 0.5 \n",
    "    else: \n",
    "        return patient_age / 100.\n",
    "\n",
    "def age_group(patient_frame):\n",
    "    patient_age = 2016 - patient_frame.year_of_birth[0]\n",
    "    if patient_age in range(0, 18):\n",
    "        return 1\n",
    "    elif patient_age in range(18, 35):\n",
    "        return 2\n",
    "    elif patient_age in range(35, 55):\n",
    "        return 3\n",
    "    elif patient_age in range(55, 70):\n",
    "        return 4\n",
    "    elif patient_age in range(70, 100):\n",
    "        return 5\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def socio_scores(patient_frame): \n",
    "    scores = {\n",
    "        'disadvantage_score': 0.,\n",
    "        'advantage_score': 0.,\n",
    "        'economic_score': 0.,\n",
    "        'occupation_score': 0.,\n",
    "        'population': 0.\n",
    "    }\n",
    "    \n",
    "    def get_score(element):        \n",
    "        score = patient_frame[element][0]\n",
    "        if isinstance(score, str):\n",
    "            return 1.\n",
    "        if score is None:\n",
    "            return 1.\n",
    "        return float(score) / 1000.\n",
    "    \n",
    "    scores.update({key: get_score(key) for key in scores})\n",
    "    return scores\n",
    "\n",
    "def diabetes(patient_frame):\n",
    "    return float(patient_frame.ChronicIllness.str.contains('Diabetes').any())\n",
    "\n",
    "def mean_script_time(patient_frame):\n",
    "    script_week_diff = pd.to_datetime(patient_frame.Prescription_Week).diff()\n",
    "    return script_week_diff[script_week_diff > pd.Timedelta(0)].mean() / pd.Timedelta(days=365*6)\n",
    "\n",
    "def system_codes(patient_frame):\n",
    "    codes = {\n",
    "         'A': 0, # Unknown\n",
    "         'C': 0, # Unknown   \n",
    "         'Z': 0, # Unknown\n",
    "         'N': 0, # NHS Script\n",
    "         'P': 0, # Private Script\n",
    "         'B': 0, # Doctors Bag Script\n",
    "         'T': 0, # Schedule Three Recordable Script\n",
    "         'R': 0, # Repatriation Script\n",
    "         'D': 0, # Dental Script\n",
    "         'E': 0, # Optometrist Script\n",
    "         'U': 0, # Nurse Practitioner Script\n",
    "         'F': 0  # Midwife Script\n",
    "        }\n",
    "\n",
    "    codes.update(patient_frame.SourceSystem_Code.value_counts(normalize=True).to_dict())\n",
    "    return codes\n",
    "\n",
    "def chronic_illness(patient_frame):\n",
    "    chronic_treatments = {\n",
    "     'Anti-Coagulant': 0,\n",
    "     'Chronic Obstructive Pulmonary Disease (COPD)': 0,\n",
    "     'ChronicIllness': 0,\n",
    "     'Depression': 0,\n",
    "     'Diabetes': 0,\n",
    "     'Epilepsy': 0,\n",
    "     'Heart Failure': 0,\n",
    "     'Hypertension': 0,\n",
    "     'Immunology': 0,\n",
    "     'Lipids': 0,\n",
    "     'Osteoporosis': 0,\n",
    "     'Urology': 0}\n",
    "    chronic_treatments.update(patient_frame.ChronicIllness.value_counts(normalize=True).to_dict())\n",
    "    return chronic_treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Compute some basic features of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-27T23:01:45.815693Z",
     "start_time": "2017-04-27T23:01:45.797149Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def feature_extract(patient_frame):\n",
    "    \"\"\"\n",
    "    Form a feature dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_dict = {\n",
    "        'gender': gender(patient_frame), \n",
    "        'age': age(patient_frame), \n",
    "        'age_group': age_group(patient_frame),\n",
    "        'mean_script_time': mean_script_time(patient_frame),\n",
    "        'target': patient_frame.Target[0]}\n",
    "    \n",
    "    feature_dict.update(system_codes(patient_frame))\n",
    "    feature_dict.update(chronic_illness(patient_frame)) \n",
    "    feature_dict.update(socio_scores(patient_frame))\n",
    "    \n",
    "    return feature_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Extract features of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Perform a random sample of patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-27T23:12:39.293830Z",
     "start_time": "2017-04-27T23:04:28.111185Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n = 100000\n",
    "#patient_ids = np.random.randint(0, 279201, n)\n",
    "#patient_data = []\n",
    "#for patient_id in tqdm.tqdm_notebook(patient_ids):\n",
    "#    patient_data.append(retrieve_patient_data(conn, patient_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('../submissions/patient_data.pkl', 'wb') as fh:\n",
    "#    pickle.dump(patient_data, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#with open('../submissions/patient_data.pkl', 'rb') as fh:\n",
    "#    patient_data = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(n_patients):\n",
    "    \"\"\"Samples patients and extracts features in one step to save memory\"\"\"\n",
    "    patient_ids = np.random.randint(0, 279201, n_patients)\n",
    "    features = []\n",
    "    for patient_id in tqdm.tqdm_notebook(patient_ids):\n",
    "        patient_data = retrieve_patient_data(conn, patient_id)\n",
    "        if len(patient_data):\n",
    "            features.append(feature_extract(patient_data))\n",
    "        \n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200000\n",
    "\n",
    "feature_frame = extract_features(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Extract features into a feature dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-27T23:21:22.074695Z",
     "start_time": "2017-04-27T23:12:39.295294Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#features = []\n",
    "#for patient in tqdm.tqdm_notebook(patient_data): \n",
    "#    if len(patient):\n",
    "#        features.append(feature_extract(patient))\n",
    "#feature_frame = pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Store the features and ?patient data? to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-26T01:49:19.786124Z",
     "start_time": "2017-04-26T01:49:15.360884Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "feature_frame.to_csv('../submissions/features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#feature_frame = pd.read_csv('../submissions/features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Explore the feature we have extracted\n",
    "\n",
    "Note: not sure here - trying out something from scikit learn but it may not be sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frame.dropna(inplace=True)\n",
    "features = feature_frame.iloc[:, 0:len(feature_frame.columns) - 1]\n",
    "target = feature_frame['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking based on ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier()\n",
    "etc.fit(features.values, target.values)\n",
    "print(pd.Series(etc.feature_importances_, index=features.columns).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_top_features = pd.Series(etc.feature_importances_, index=features.columns).sort_values(ascending=False)[0:10].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking based on RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 10)\n",
    "rfe_fit = rfe.fit(features.values, target.values)\n",
    "print(\"Num Features: {}\".format(rfe_fit.n_features_))\n",
    "print(\"Selected Features: \\n{}\".format(pd.Series(rfe_fit.support_, index=features.columns)))\n",
    "print(\"Feature Ranking: {}\".format(rfe_fit.ranking_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking based on SelectKBest\n",
    "\n",
    "This doesn't seem to deal with with some of the features but I haven't taken the time to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# feature extraction\n",
    "kbest = SelectKBest(score_func=chi2, k=10)\n",
    "kbest_fit = kbest.fit(features, target)\n",
    "\n",
    "# summarize scores\n",
    "print(pd.Series(kbest_fit.scores_, index=features.columns).sort_values())\n",
    "reduced_features = kbest_fit.transform(features.values)\n",
    "# summarize selected features\n",
    "print(reduced_features[0:9,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=2)\n",
    "pca_fit = pca.fit(features.values)\n",
    "# summarize components\n",
    "print(\"Explained Variance: {}\".format(pca_fit.explained_variance_ratio_))\n",
    "print(pca_fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nathan's feature summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-27T23:43:09.360431Z",
     "start_time": "2017-04-27T23:43:09.289456Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "means = feature_frame.groupby('target').mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a method to cull features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select important features based on ETC\n",
    "#features = feature_frame[etc_top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unimportant features based on RFE\n",
    "rfe_support = pd.Series(rfe_fit.support_, index=features.columns)\n",
    "features = feature_frame[rfe_support[rfe_support == True].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Try out a set of different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Note: the feature matrix is usually transformed to have zero mean and unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = features.dropna().values #feature_frame.dropna().drop('target', axis=1).values\n",
    "y = feature_frame.dropna().target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-27T23:43:16.230490Z",
     "start_time": "2017-04-27T23:43:16.043373Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment this to use features based on PCA\n",
    "#pca = PCA(n_components=4)\n",
    "#pca_fit = pca.fit(X)\n",
    "#X_transformed = pca_fit.transform(X, y)\n",
    "\n",
    "# Uncomment this to use features based on SelectKBest\n",
    "#kbest = SelectKBest(score_func=chi2, k=10)\n",
    "#kbest_fit = kbest.fit(X, y)\n",
    "#X_transformed = kbest_fit.transform(X)\n",
    "\n",
    "X_transformed = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Partition the data into test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-27T23:43:22.247779Z",
     "start_time": "2017-04-27T23:43:22.193226Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-27T23:49:27.110289Z",
     "start_time": "2017-04-27T23:43:23.169545Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ('Random Forrest', RandomForestClassifier()),\n",
    "    ('Decision Tree', DecisionTreeClassifier()),\n",
    "    ('Adaboost',AdaBoostClassifier() ),\n",
    "    ('xgboost Gradient boosted decition tree', xgboost.XGBClassifier()), \n",
    "    ('Gradient boosting classifier', GradientBoostingClassifier()),    \n",
    "    ('Bagging', BaggingClassifier()),\n",
    "    ('Bernoulli Naive Bayes', BernoulliNB()),\n",
    "    ('MLPClassifier (NN)', MLPClassifier()),\n",
    "    ('LDA', LinearDiscriminantAnalysis())\n",
    "    #('SVM',SVC(probability=True) # too slow!\n",
    "]\n",
    "\n",
    "for name, clf in classifiers:\n",
    "    print('Classifier: {}'.format(name))\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    y_true, y_pred = y_test, clf.predict(X_test) \n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Score {}'.format(score))\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Form a submission\n",
    "\n",
    "Perform the prediction in 1000 patient \"chunks\" to speed up the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T04:11:55.420137Z",
     "start_time": "2017-04-28T04:11:53.637869Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier().fit(X, y)#xgboost.XGBClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T04:11:56.593098Z",
     "start_time": "2017-04-28T04:11:56.508965Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../submissions/diabetes_submission_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T04:11:57.710584Z",
     "start_time": "2017-04-28T04:11:57.696473Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chunks = submission.groupby(np.arange(len(submission)) // 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T04:57:00.138028Z",
     "start_time": "2017-04-28T04:12:00.246505Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for group, frame in tqdm.tqdm_notebook(chunks):\n",
    "    \n",
    "    # Extract the features\n",
    "    data = [feature_extract(retrieve_patient_data(conn, x)) for x in frame.Patient_ID.values]\n",
    "    \n",
    "    # Construct prediction X matrix\n",
    "    features = pd.DataFrame(data)\n",
    "    \n",
    "    # filter features\n",
    "    features = features[rfe_support[rfe_support == True].index]    \n",
    "    \n",
    "    pred_x = features.values #features.drop('target', axis=1).values\n",
    "    pred_x[np.isnan(pred_x)] = 0.0\n",
    "    \n",
    "    # Apply the standard transform prior to fitting. \n",
    "    pred_x = StandardScaler().fit_transform(pred_x)\n",
    "    \n",
    "    # Fit the model\n",
    "    submission.Diabetes[frame.index] = model.predict_proba(pred_x)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-28T00:45:50.127536Z",
     "start_time": "2017-04-28T00:45:49.452332Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../submissions/kaggle_four.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "189px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
